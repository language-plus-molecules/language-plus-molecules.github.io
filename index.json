[{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"6ba1f51165e17686c28fe9c804fdc145","permalink":"https://language-plus-molecules.github.io/authors/kyunghyun-cho/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/kyunghyun-cho/","section":"authors","summary":"","tags":null,"title":"Kyunghyun Cho","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"19c1c0772353e4ae5efdcc30337885b7","permalink":"https://language-plus-molecules.github.io/authors/elsa-olivetti/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/elsa-olivetti/","section":"authors","summary":"","tags":null,"title":"Elsa Olivetti","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"3e2c712f091f34aef88842df9622ac8e","permalink":"https://language-plus-molecules.github.io/authors/marinka-zitnik/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/marinka-zitnik/","section":"authors","summary":"","tags":null,"title":"Marinka Zitnik","type":"authors"},{"authors":["manling-li"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"e386ae0191c2c53249f48f74e4bb9d69","permalink":"https://language-plus-molecules.github.io/authors/manling-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/manling-li/","section":"authors","summary":"","tags":null,"title":"Manling Li","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"51fa29fb3c4e83fc80169afc25847605","permalink":"https://language-plus-molecules.github.io/authors/qingyun-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/qingyun-wang/","section":"authors","summary":"","tags":null,"title":"Qingyun Wang","type":"authors"},{"authors":null,"categories":null,"content":"March 21, 2024 hybrid in Malta \u0026amp; Remote\nSynthesizing Language and Molecules for Scientific Insight and Discovery\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c7ebea0ce748e947a2471b5fe09a168d","permalink":"https://language-plus-molecules.github.io/tutorial/intro/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/tutorial/intro/","section":"tutorial","summary":"March 21, 2024 hybrid in Malta \u0026 Remote\nSynthesizing Language and Molecules for Scientific Insight and Discovery","tags":null,"title":"Language + Molecules  \n{style=\"color: white; font-size: 4rem; text-shadow: 0 0 2px black, 0 0 2px black, 0 0 2px black, 0 0 2px black;\"}    \n@ EACL 2024 Tutorial\n{style=\"color: white; font-size: 3rem; text-shadow: 0 0 2px black, 0 0 2px black, 0 0 2px black, 0 0 2px black;\"}\n","type":"tutorial"},{"authors":null,"categories":null,"content":"Welcome to the Language + Molecules Tutorial! Join us for this introductory tutorial targetted at NLP researchers with no knowledge of chemistry as we explore cutting-edge new work in the integration of molecules and natural language, with exciting applications such as developing new drugs, materials, and chemical processes.\nClimate change, access to food and water, pandemics— these words, when uttered, immediately summon to mind global challenges with possible disastrous outcomes. Molecular solutions will be critical to addressing these global problems on scales of complexity never-before-seen. However, they exist in extremely large search spaces, which makes AI tools a necessity. Excitingly, the chemistry field is posed to be substantially accelerated via multimodal models combining language with molecules and drug structures.\nStay tuned by following us on Twitter @lang_plus_mols.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"180db4a2e8275c32da9267a97428ed6d","permalink":"https://language-plus-molecules.github.io/tutorial/about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/tutorial/about/","section":"tutorial","summary":"Welcome to the Language + Molecules Tutorial! Join us for this introductory tutorial targetted at NLP researchers with no knowledge of chemistry as we explore cutting-edge new work in the integration of molecules and natural language, with exciting applications such as developing new drugs, materials, and chemical processes.","tags":null,"title":"","type":"tutorial"},{"authors":null,"categories":null,"content":" Outline [180 min.] Applying language models to the scientific domain is becoming increasingly popular due to its potential impact for accelerating scientific discovery (Hope et al., 2022). Beyond extracting information from scientific literature, NLP has the possibility to increase control of the scientific discovery process, which can be achieved through multimodal representations and generative language models.\n1. Background [60 min.] Scientific Information Extraction [15 min.] To start, we will provide a high-level overview on traditional NLP tasks used for scientific discovery (e.g., named entity recognition, entity linking, and relation extraction), as well as recent domain-specific LLMs designed for superior performance on scientific tasks (Beltagy et al., 2019).\nWhat is a molecule? [15 min.] Half of the title is molecules, but what is one? We will start from scratch and discuss what a molecule actually is, including the basic constituents of molecules, atoms and bonds, and how they essentially form graph structures. Then, we will focus on molecular string languages, which are a key building block for chemical language models. We will discuss tradeoffs of these languages (Grisoni, 2023; Weininger, 1988; O’Boyle and Dalke, 2018; Krenn et al., 2020; Cheng et al., 2023). Krenn et al. (2020) proposes a formal grammar approach, which may particularly interest the ACL community.\nMolecule Design using Language Models [15 min.] Now that we know what a molecule is, we will overview recent work applying NLP techniques to these molecular languages with impressive results. LLMs are traineded with adapted pretraining techniques from (natural) language models to learn molecule representation from large collections of such molecule strings (Frey et al., 2022; Chithrananda et al., 2020; Ahmad et al., 2022; Fabian et al., 2020; Schwaller et al., 2021; NVIDIA Corporation, 2022; Flam-Shepherd and Aspuru-Guzik, 2023; Tysinger et al., 2023). Applications including molecule and material generation, property prediction, and protein binding site prediction.\nDrug Discovery – A Brief Primer [15 min.] Ok, so NLP is being used for molecules now. What can we do with it?—here, we present a brief overview of drug discovery–an important but challenging problem. Historically, molecular discovery has commonly been done by humans who design and build individual molecules, but this can cost over a billion dollars and take over ten years (Gaudelet et al., 2021). We’ll discuss a little of the process here, including non-NLP deep learning methods, so that we know how to improve it.\n2. Integrating Language with Molecules [95 min.] What does natural language have to offer? [15 min.] At least at first, integrating languages and molecules seems like an odd idea. Here, we’ll start an interactive discussion with the audience on what they think potential benefits might be. We’ll make sure to mention the following major advantages, as discussed in the recent survey (Zhang et al., 2023, Section 10.3.3 “Natural Language-Guided Scientific Discovery”):\nGenerative Modeling: One of the largest problems in current LLMs—hallucination—becomes a strength for discovering molecules with high-level functions and abstract properties. In particular, language is compositional by nature (Szabó, 2020; Partee et al., 1984; Han et al., 2023), and therefore holds promise for composing these high-level properties (e.g., antimalarial) (Liu et al., 2022). Bridging Modalities: Language can serve to “bridge” between modalities for scarce data. Domain Understanding: Grounding language models into external real world knowledge can improve understanding of unseen molecules and advance many emerging tasks, such as experimental procedure planning, which use LLMs as scientific agents. Democratization: Language enables scientists without computational expertise to leverage advances in scientific AI. Do I want multimodality? [5 min.] An important, yet often overlooked, question in multimodal NLP is to ask: do I need multimodality? For example, if one wants to extract reactions from the literature, a text-to-text model (Vaucher et al., 2020) might be sufficient. However, editing a drug with high-level instructions requires language (Liu et al., 2023a; Fang et al., 2023). Here, we will dive into this question and discuss example scenarios with the audience for how to answer it.\nIntegrating Modalities [30 min.] Ok, we’ve decided we want or need multimodality. Next, we need to discuss how people are currently tackling this—we’ll start with two primary methods, bi-encoder models and joint representation models.\nBi-Encoder Models (and beyond) Bi-Encoder Models consist of an encoder branch for text and a branch for molecules. They have the advantage of not requiring direct, early integration of the two modalities, allowing existing single-modal models to be integrated. Representative examples we will discuss include Text2Mol (Edwards et al., 2021), CLAMP (Seidl et al., 2023), and …","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9a270696f159437547da7a4fd094c9d8","permalink":"https://language-plus-molecules.github.io/tutorial/outline/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/tutorial/outline/","section":"tutorial","summary":"Outline [180 min.] Applying language models to the scientific domain is becoming increasingly popular due to its potential impact for accelerating scientific discovery (Hope et al., 2022). Beyond extracting information from scientific literature, NLP has the possibility to increase control of the scientific discovery process, which can be achieved through multimodal representations and generative language models.","tags":null,"title":"Outline","type":"tutorial"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"366267f0f5d43c0eaea9dbebfdb07e78","permalink":"https://language-plus-molecules.github.io/home_backup/workshops/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home_backup/workshops/","section":"home_backup","summary":"","tags":null,"title":"Workshops","type":"home_backup"},{"authors":null,"categories":null,"content":" Molecule Representations and Language Models: “Smiles, a chemical language and information system. 1. introduction to methodology and encoding rules.” Weininger, 1988. “Self-referencing embedded strings (selfies): A 100% robust molecular string representation.” Krenn et al., 2020. “Group selfies: a robust fragment-based molecular string representation.” Cheng et al., 2023. “Chemberta: Large-scale self-supervised pretraining for molecular property prediction.” Chithrananda et al., 2020. “Chemberta-2: Towards chemical foundation models.” Ahmad et al., 2022. “Can we quickly learn to “translate” bioactive molecules with transformer models?” Tysinger et al., 2023. Molecule-Language Modeling: “Text2Mol: Cross-modal molecule retrieval with natural language queries.” Edwards et al., 2021. “A deep-learning system bridging molecule structure and biomedical text with comprehension comparable to human professionals.” Zeng et al., 2022. “Translation between molecules and natural language.” Edwards et al., 2022. “A molecular multimodal foundation model associating molecule graphs with natural language.” Su et al., 2022. “Multi-modal molecule structure-text model for text-based retrieval and editing.” Liu et al., 2022. “Adversarial modality alignment network for cross-modal molecule retrieval.” Zhao et al., 2023. “Gimlet: A unified graph-text model for instruction-based molecule zero-shot learning.” Zhao et al., 2023. “Molxpt: Wrapping molecules with text for generative pre-training.” Liu et al., 2023. “Multilingual translation for zero-shot biomedical classification using biotranslator.” Xu et al., 2023. “Chatgpt-powered conversational drug editing using retrieval and domain feedback.” Liu et al., 2023. Applications: “Drug discovery chemistry: a primer for the non-specialist.” Jordan et al., 2009. “Organic photovoltaics.” Kippelen et al., 2009. “Kinase inhibitors: the road ahead.” Ferguson et al., 2018. LLMs as Scientific Agents: “Emergent autonomous scientific research capabilities of large language models.” Boiko et al., 2023. “ChemCrow: Augmenting large-language models with chemistry tools.” Bran et al., 2023. “Do large language models understand chemistry? a conversation with chatgpt.” Castro Nascimento et al., 2023. “Assessment of chemistry knowledge in large language models that generate code.” White et al., 2023. Survey: “Artificial intelligence for science in quantum, atomistic, and continuum systems.” Zhang et al., 2023. Section 10.3.3 “Natural Language-Guided Scientific Discovery”. We won’t require reading these beforehand to ensure the tutorial is introductory.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0329dbc51f44cc7402585921d67bda57","permalink":"https://language-plus-molecules.github.io/tutorial/reading_list/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/tutorial/reading_list/","section":"tutorial","summary":"Molecule Representations and Language Models: “Smiles, a chemical language and information system. 1. introduction to methodology and encoding rules.” Weininger, 1988. “Self-referencing embedded strings (selfies): A 100% robust molecular string representation.","tags":null,"title":"Reading List (Subject to Change)","type":"tutorial"},{"authors":null,"categories":null,"content":"To be released.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"05b178aca1a0340e4f69b15d4355bacd","permalink":"https://language-plus-molecules.github.io/tutorial/interactive_example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/tutorial/interactive_example/","section":"tutorial","summary":"To be released.","tags":null,"title":"An Interactive Example","type":"tutorial"},{"authors":null,"categories":null,"content":"Check out frequently asked questions…\nWhen will I recieve my ticket? You will receive your ticket to your e-mail immediately after successful payment.\nDo you provide travel and accommodation for speakers? Yes, both accommodation and travel costs for selected speakers are covered by Hugo Summit.\nDo I need a visa? If you are an EU citizen or member of the Schengen area you don’t need any visa.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"a12b6ed22884ec8321c13519d3946f33","permalink":"https://language-plus-molecules.github.io/home_backup/faq/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home_backup/faq/","section":"home_backup","summary":"Check out frequently asked questions…\nWhen will I recieve my ticket? You will receive your ticket to your e-mail immediately after successful payment.\nDo you provide travel and accommodation for speakers?","tags":null,"title":"FAQ","type":"home_backup"},{"authors":null,"categories":null,"content":" ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ea063774fa736f845abad5da5532ee63","permalink":"https://language-plus-molecules.github.io/home_backup/sponsors/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home_backup/sponsors/","section":"home_backup","summary":" ","tags":null,"title":"Sponsors","type":"home_backup"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchmey’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://language-plus-molecules.github.io/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/example/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Workshop","type":"event"}]